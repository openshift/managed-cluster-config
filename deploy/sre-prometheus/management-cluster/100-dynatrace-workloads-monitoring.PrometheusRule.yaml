apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: sre-dynatrace-workloads
    role: alert-rules
  name: sre-dynatrace-workloads
  namespace: openshift-monitoring
spec:
  groups:
    - name: sre-dynatrace-workloads-failing
      rules:
        - alert: DynatraceMonitoringStackDownSRE
          expr: |
            absent(kube_deployment_status_replicas{deployment="dynatrace-operator", namespace="dynatrace"}) or
            absent(kube_deployment_status_replicas{deployment="dynatrace-webhook", namespace="dynatrace"}) or
            absent(kube_deployment_status_replicas{deployment="opentelemetry-dynatrace-collector", namespace="dynatrace"}) or
            absent(kube_statefulset_status_replicas{statefulset=~".*-activegate", namespace="dynatrace"}) or
            absent(kube_daemonset_status_desired_number_scheduled{daemonset=~".*-oneagent", namespace="dynatrace"})
          for: 15m
          labels:
            namespace: dynatrace
            severity: critical
          annotations:
            summary: "Dynatrace Workload(s) are absent or have failed to deploy on the Management Cluster"
            description: |
              The following Dynatrace Workload(s) are absent or have failed to be deployed the Management Cluster for last 15 mins:
              {{ if $labels.deployment }} {{$labels.deployment}} Deployment {{end}}
              {{ if $labels.daemonset }} {{ $labels.daemonset }} Daemonset {{end}}
              {{ if $labels.statefulset }} {{$labels.statefulset}} Statefulset {{end}}
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/alerts/DynatraceMonitoringStackDownSRE.md

    - name: sre-dynatrace-monitoring-stack-degraded
      rules:
        - alert: DynatraceOperatorDegradedSRE
          expr: (sum(kube_deployment_spec_replicas{deployment="dynatrace-operator", namespace="dynatrace"}) without (deployment, instance, pod)) - (sum(kube_deployment_status_replicas_available{deployment="dynatrace-operator", namespace="dynatrace"}) without (deployment, instance, pod)) > 0
          for: 15m
          labels:
            namespace: dynatrace
            severity: warning
          annotations:
            summary: "The Dynatrace Operator is Degraded"
            description: "{{$value}} replicas are not running out of total required replicas for the Dynatrace Operator"
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/alerts/DynatraceOperatorDegradedSRE.md

        - alert: DynatraceWebhookDegradedSRE
          expr: (sum(kube_deployment_spec_replicas{deployment="dynatrace-webhook", namespace="dynatrace"}) without (deployment, instance, pod)) - (sum(kube_deployment_status_replicas_available{deployment="dynatrace-webhook", namespace="dynatrace"}) without (deployment, instance, pod)) > 0
          for: 15m
          labels:
            namespace: dynatrace
            severity: warning
          annotations:
            summary: "Dynatrace Webhook is Degraded"
            description: "{{$value}} replicas are not running out of total required replicas for the Dynatrace Webhook"
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/alerts/DynatraceWebhookDegradedSRE.md

        - alert: DynatraceOpenTelemetryCollectorDownSRE
          expr: kube_deployment_status_replicas_unavailable{namespace="dynatrace", deployment="opentelemetry-dynatrace-collector"}  > 0
          for: 5m
          labels:
            namespace: dynatrace
            severity: critical
          annotations:
            summary: "Dynatrace OTEL Collector is Degraded"
            description: "{{$value}} replicas are not running out of total required replicas for the OpenTelemetry Dynatrace Collector"
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/alerts/DynatraceOpenTelemetryCollectorDownSRE.md

        - alert: DynatracePodRestartsStuckSRE
          expr: kube_pod_container_status_restarts_total{namespace="dynatrace"} > 0 and increase(kube_pod_container_status_restarts_total{namespace="dynatrace"}[15m]) > 0
          for: 15m
          labels:
            namespace: dynatrace
            severity: warning
          annotations:
            summary: "Pod Restarts Stuck Alert"
            description: "At least one pod in the 'dynatrace' namespace has been stuck in restarts for the last 15 minutes."
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/alerts/DynatracePodRestartsStuckSRE.md

        - alert: DynatraceDynakubeComponentsDegradedSRE
          annotations:
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/docs/troubleshooting/dynakube.md
            description: HCP workload oneagent daemonset in the 'dynatrace' namespace is missing for 60 minutes.
            summary: HCP workload oneagent daemonset missing
          expr: |
            absent(kube_pod_info{namespace="dynatrace", created_by_kind="DaemonSet", created_by_name=~".*oneagent"})
          for: 60m
          labels:
            daemonset: hcp-workload-oneagent
            namespace: dynatrace
            severity: critical
            state: missing

        - alert: DynatraceDynakubeComponentsDegradedSRE
          expr: (kube_daemonset_status_desired_number_scheduled{namespace="dynatrace", daemonset=~"hs-mc.+"} - kube_daemonset_status_number_ready{namespace="dynatrace", daemonset=~"hs-mc.+"}) > 0
          for: 60m
          labels:
            namespace: dynatrace
            severity: critical
            daemonset: hcp-workload-oneagent
            state: degraded
          annotations:
            summary: "HCP workload oneagent pods degraded"
            description: "At least one HCP workload oneagent pod in the 'dynatrace' namespace is not available for 60 minutes."
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/docs/troubleshooting/dynakube.md

        - alert: DynatraceDynakubeComponentsDegradedSRE
          annotations:
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/docs/troubleshooting/dynakube.md
            description: Activegate statefulset in the 'dynatrace' namespace is missing for 60 minutes.
            summary: Dynatrace Activegate statefulset missing
          expr: |
            absent(kube_statefulset_metadata_generation{namespace="dynatrace", statefulset=~".*activegate"})
          for: 60m
          labels:
            namespace: dynatrace
            severity: critical
            statefulset: activegate
            state: missing

        - alert: DynatraceDynakubeComponentsDegradedSRE
          expr: (kube_statefulset_replicas{namespace="dynatrace", statefulset=~"hs-mc-.+"} - kube_statefulset_status_replicas_ready{namespace="dynatrace", statefulset=~"hs-mc.+"}) > 0
          for: 60m
          labels:
            namespace: dynatrace
            severity: critical
            statefulset: activegate
            state: degraded
          annotations:
            summary: "Dynatrace Activegate pods degraded"
            description: "At least one activegate pod in the 'dynatrace' namespace is not available for 60 minutes."
            SOP: https://github.com/openshift/ops-sop/blob/master/dynatrace/docs/troubleshooting/dynakube.md
